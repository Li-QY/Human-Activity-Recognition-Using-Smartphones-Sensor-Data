{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0STxdZQOsgj"
      },
      "source": [
        "# プロジェクト"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyMjylZAOsgn"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.svm import SVC,LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import RidgeClassifier,SGDClassifier,PassiveAggressiveClassifier,LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier,StackingClassifier,ExtraTreesClassifier\n",
        "from sklearn.feature_selection import RFECV,chi2,SelectKBest, SelectPercentile\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier,RadiusNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV,RandomizedSearchCV,StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "root_dir= \"data/\"\n",
        "nsample = 3000\n",
        "features = list()\n",
        "with open('features.txt') as f:\n",
        "    features = [line.split()[1] for line in f.readlines()]\n",
        "print('No of Features: {}'.format(len(features)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWXf36u1Osgq"
      },
      "outputs": [],
      "source": [
        "# 白ワインデータセットの読み込み\n",
        "X_train = pd.read_csv(root_dir+\"X_train.csv\",header=None)\n",
        "# X_train.columns=features\n",
        "y_train = pd.read_csv(root_dir+\"y_train.csv\",names=['Activity'],header=None, squeeze=True)\n",
        "X_test = pd.read_csv(root_dir+\"X_test.csv\",header=None)\n",
        "# X_test.columns=features\n",
        "\n",
        "# train = X_train.copy()\n",
        "# y_train_labels = y_train.map({1: 'WALKING', 2:'WALKING_UPSTAIRS',3:'WALKING_DOWNSTAIRS',\\\n",
        "#                 4:'SITTING', 5:'STANDING',6:'LAYING'})\n",
        "# train['subject'] = pd.read_csv('subject_train.csv',header=None)\n",
        "# train['Activity'] = y_train\n",
        "# train['ActivityName'] = y_train_labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_train.hist(figsize=(50,50))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_train.skew().sort_values(ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_train.std().sort_values(ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print('No of duplicates in train: {}'.format(sum(X_train.duplicated())))\n",
        "# print('No of duplicates in test : {}'.format(sum(X_test.duplicated())))\n",
        "# print('We have {} NaN/Null values in train'.format(X_train.isnull().values.sum()))\n",
        "# print('We have {} NaN/Null values in test'.format(X_test.isnull().values.sum()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# y_train.hist(figsize=(5,5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sns.set_style('whitegrid')\n",
        "# plt.rcParams['font.family'] = 'Dejavu Sans'\n",
        "\n",
        "# plt.figure(figsize=(16,8))\n",
        "# plt.title('Data provided by each user', fontsize=20)\n",
        "# sns.countplot(x='subject',hue='ActivityName', data = train)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_train.corr()['Activity'].sort_values().head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr = X_train.corr()\n",
        "flag = np.full((corr.shape[0]),True, dtype=bool)\n",
        "for i in range(corr. shape[0]):\n",
        "    for j in range(i+1, corr. shape[0]):\n",
        "        if corr.iloc[i,j] >= 0.85:\n",
        "            if flag[j]:\n",
        "                flag[j] = False\n",
        "select = X_train.columns[flag].tolist()\n",
        "X_train = X_train[select]\n",
        "X_test = X_test[select]\n",
        "print(X_train.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Outliers検出"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_train['Activity'] = y_train\n",
        "# for i in X_train.columns.values:\n",
        "#     u = np.median(X_train[i])\n",
        "#     s = np.std(X_train[i])\n",
        "#     idx = (X_train[i]<u+5*s)&(X_train[i]>u-5*s)\n",
        "#     X_train = X_train[idx]\n",
        "#     y_train = y_train[idx]\n",
        "# X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Define classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# standard_scaler = StandardScaler()\n",
        "# standard_scaler.fit(X_train)\n",
        "# X = standard_scaler.transform(X_train)\n",
        "X = X_train\n",
        "y = y_train\n",
        "\n",
        "# 訓練データとテストデータに分割\n",
        "X_train,X_val, y_train,y_val= train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "y_train = np.array(y_train).flatten()\n",
        "X_train = np.array(X_train)\n",
        "\n",
        "y_val = np.array(y_val).flatten()\n",
        "X_val = np.array(X_val)\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "# X_test = standard_scaler.transform(X_test)\n",
        "\n",
        "X_train.shape,y_train.shape,X_val.shape,y_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Models after hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {'DecisionTreeClassifier    ':DecisionTreeClassifier(),\n",
        "          'SVC                       ':SVC(),\n",
        "          'LogisticRegression        ':LogisticRegression(),\n",
        "          'GradientBoostingClassifier':GradientBoostingClassifier(),\n",
        "          'Ridge                     ':RidgeClassifier(),\n",
        "          'LGBMClassifier            ':LGBMClassifier(),\n",
        "          'RandomForestClassifier    ':RandomForestClassifier(),\n",
        "          'XGBClassifier             ':XGBClassifier()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "{'DecisionTreeClassifier    ': 'Train: 1.0000, Val: 0.9331',\n",
        " 'SVC                       ': 'Train: 0.9870, Val: 0.9823',\n",
        " 'LogisticRegression        ': 'Train: 0.9983, Val: 0.9803',\n",
        " 'GradientBoostingClassifier': 'Train: 1.0000, Val: 0.9921',\n",
        " 'LGBMClassifier            ': 'Train: 1.0000, Val: 0.9931',\n",
        " 'RandomForestClassifier    ': 'Train: 1.0000, Val: 0.9754',\n",
        " 'XGBClassifier             ': 'Train: 1.0000, Val: 0.9931'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "tokwSCu_Osgr",
        "outputId": "bba70578-2ea0-4bce-bf95-36f9055247c0"
      },
      "outputs": [],
      "source": [
        "# 分類モデル\n",
        "# scorelist = {}\n",
        "# for key, model in models.items():\n",
        "#     model.fit(X_train, y_train) # 訓練データで学習\n",
        "#     yHatTrain = model.predict(X_train)\n",
        "#     yHatVal = model.predict(X_val)\n",
        "#     scorelist[key] = 'Train: {:.4f}, Val: {:.4f}'.format(len((np.where(yHatTrain == y_train))[0])*1.0/X_train.shape[0],\n",
        "#                         len((np.where(yHatVal == y_val))[0])*1.0/X_val.shape[0])\n",
        "#     yHatTest = model.predict(X_test)\n",
        "#     np.savetxt(root_dir+'fs0.84result_'+key+'.txt', yHatTest)\n",
        "# scorelist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# penalty='l1',dual=False\n",
        "# parameters = {\n",
        "#               'max_depth': [1, 5, 10, 15, 20, 25, 30, 35],\n",
        "#               'learning_rate': [0.01, 0.02, 0.05, 0.1, 0.15],\n",
        "#               'feature_fraction': [0.6, 0.7, 0.8, 0.9, 0.95],\n",
        "#               'bagging_fraction': [0.6, 0.7, 0.8, 0.9, 0.95],\n",
        "#               'bagging_freq': [2, 4, 5, 6, 8],\n",
        "#               'lambda_l1': [0, 0.1, 0.4, 0.5, 0.6],\n",
        "#               'lambda_l2': [0, 10, 15, 35, 40],\n",
        "#               'cat_smooth': [1, 10, 15, 20, 35]\n",
        "# }7,min_child_weight=2,reg_alpha=0.6,scale_pos_weight=1\n",
        "# model = XGBClassifier()\n",
        "# model.fit(X_train, y_train)\n",
        "# yHatTrain = model.predict(X_train)\n",
        "# yHatVal = model.predict(X_val)\n",
        "\n",
        "# print('Train: {:.6f}, Val: {:.6f}'.format(len((np.where(yHatTrain == y_train))[0])*1.0/X_train.shape[0],\n",
        "#                         len((np.where(yHatVal == y_val))[0])*1.0/X_val.shape[0]))\n",
        "# yHatTest = model.predict(X_test)\n",
        "# np.savetxt(root_dir+'fs0.85ssresultXGBClassifier.txt', yHatTest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# paralist = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "for i in range(25,31):\n",
        "    model = LGBMClassifier(max_depth=18,min_child_samples=i)\n",
        "    model.fit(X_train, y_train)\n",
        "    yHatTrain = model.predict(X_train)\n",
        "    yHatVal = model.predict(X_val)\n",
        "    print('mcs: {}, Train: {:.6f}, Val: {:.6f}'.format(i, len((np.where(yHatTrain == y_train))[0])*1.0/X_train.shape[0],\n",
        "                        len((np.where(yHatVal == y_val))[0])*1.0/X_val.shape[0]))\n",
        "    yHatTest = model.predict(X_test)\n",
        "    np.savetxt(root_dir+'result_LGBM_mcs'+ str(i) + '.txt', yHatTest)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
